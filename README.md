# Дистилляция ризонинга в малые языковые модели

## Описание проекта

Данный проект посвящен исследованию методов дистилляции способности к рассуждению (reasoning) из больших языковых моделей (LLM) в малые модели с использованием подхода **Cascade Mixture of Experts (CMoE)**.

### Цель исследования
Исследование эффективных методов передачи способности к рассуждению от больших LLM к малым языковым моделям для решения задач Question Answering (QA).

### Основные задачи
- **Генерация датасета рассуждений** больших LLM при решении QA задач
- **Разработка пайплайна обучения** малых LLM
- **Обучение малых LLM** на полученных данных рассуждений
- **Анализ результатов** и сравнение различных подходов

## Данные

### Бенчмарк ruMMLU
- **MERА** - ~10,000 высококачественных записей
- **4 основные категории**, разбитые на **57 поддоменов**:
  - Social & Humanities
  - Natural Science  
  - Math & CS
  - Other

**Ссылка на бенчмарк**: [ruMMLU на платформе MERA](https://mera.a-ai.ru/en/text/tasks/9)

### Сгенерированные данные рассуждений
- **Qwen3-235B**: ~8,500 сэмплов рассуждений (~85% точность)
- **Llama3.3-70B**: ~8,000 сэмплов рассуждений (~80% точность)

## Модели-учителя

### Выбранные модели
- **Qwen3-235B** и **Llama3.3-70B**
- **Преимущества**:
  - Open-source модели
  - Большое разнообразие размеров
  - Надежность и популярность в сообществе

### Альтернативная гипотеза №1: Русскоязычные LLM-учителя
**Проблемы**:
- Дороговизна on-cloud решений
- Сложность развертывания на собственных ресурсах
- Малое разнообразие моделей
- Закрытость архитектуры

![Русскоязычные LLM](images/ru_llm.png)

## Архитектура CMoE

### Проблема baseline-подхода
- **Baseline-модель дистилляции**: слишком резкий скачок в размерности
- **Базовая каскадная модель**: стандартный подход с плавным уменьшением размерности

![Baseline модели](images/baseline.png)

### Идея CMoE
Каскадная дистилляция рассуждений смеси экспертов (CMoE) в малые языковые модели.

### Архитектурные особенности
- **Промежуточная "модель специалиста"** (~10B) вместо "резкого" скачка
- **Обучение модели специалиста** на одном выделенном домене
- **LoRA** как основной метод дообучения

![Архитектура CMoE](images/cmoe_architecture.png)

## Результаты

### Сравнение CMoE и прямой дистилляции

#### CMoE (Qwen) - 79.3% общая точность
- **Social & Humanities**: 82.90%
- **Other**: 77.97%
- **Math & CS**: 70.70%
- **Natural Science**: 85.58%

#### Прямая дистилляция (Qwen) - 72.2% общая точность
- Из Qwen3-235B в Qwen3-14B на неразделенном датасете

### Итоговые результаты
- **Qwen3-1.7B**: 60.93% правильных ответов
- **Qwen3-4B**: 81.3% правильных ответов

![Сравнение результатов](images/results_comparison.png)

## Альтернативные гипотезы

### Гипотеза №2: Knowledge-Augmented Reasoning Distillation (KARD)
**Идея**: Улучшение результата за счет подачи дополнительного релевантного контекста

**Результат**: При ограниченных ресурсах эффективность KARD резко снижается и приводит к "зашумлению" нерелевантным контекстом (33.4% правильных ответов при 200k статей с Wikipedia в контексте Qdrant)

![KARD архитектура](images/kard_arhc.png)

**Ссылка на статью**: [Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks](https://arxiv.org/abs/2305.18395)

### Гипотеза №3: Seq2seq для дистилляции
- **FredT5-1.7B**: 25% правильных ответов
- **ruT5-large (737M)**: 27.91% правильных ответов
- **VikhrT5-3B**: 0.33% правильных ответов (с добавлением спецтокенов в токенайзер)

![seq2seq results](images/kard_arhc.png)


## Выводы

### Успешные результаты
- **CMoE** позволяет получить **~6-7% прирост** к итоговому качеству
- **Ускорение обучения в 4 раза** по сравнению с прямым подходом

### Отклоненные гипотезы
- **Гипотеза №1** (русскоязычные LLM-учителя): дороговизна генерации
- **Гипотеза №2** (KARD): малая эффективность при ограниченных ресурсах
- **Гипотеза №3** (seq2seq): низкая способность к рассуждению

## Дальнейшая работа

### 1. Масштабирование датасета
- **Расширение "золотого датасета"** с использованием новых источников (t-tech/T-Wix и др.)
- **Ожидаемый результат**: повышение разнообразия и обобщающей способности моделей

### 2. Исследование других архитектур
- **Проверка CMoE** на различных open-source моделях
- **Ожидаемый результат**: формулировка архитектурных особенностей других LLM

### 3. Систематическая оценка
- **Полное сравнительное тестирование** всех обученных моделей на релевантных бенчмарках
- **Ожидаемый результат**: выявление самой эффективной архитектуры, гиперпараметров и подходов для данной задачи

## Структура проекта

```

```
